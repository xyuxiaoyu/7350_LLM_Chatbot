<!DOCTYPE HTML>
<html lang="en-US">
	<head>
		<meta charset="UTF-8">
		<meta http-equiv="x-ua-compatible" content="ie=edge">
		<title>Large Language Model and Chatbot</title>
		<meta name="description" content="">
		<meta name="viewport" content="width=device-width, initial-scale=1">
		<!-- Favicon Icon -->
		<link rel="icon"  type="image/png" href="assets/images/favicon.png">		
		<link rel="stylesheet" type="text/css" href="assets/css/bootstrap.min.css"/>
		<link rel="stylesheet" type="text/css" href="venobox/venobox.css"/>
		<link rel="stylesheet" type="text/css" href="assets/css/plugin_theme_css.css"/>
		<link rel="stylesheet" type="text/css" href="assets/css/style.css"/>        
		<!--<link rel="stylesheet" type="text/css" href="style.css"/>-->
		<link rel="stylesheet" type="text/css" href="assets/css/responsive.css"/>
		<!-- modernizr js -->	
		<script src="assets/js/vendor/modernizr-2.8.3.min.js"></script>		
		
	</head>
<body>
<div class="em40_header_area_main">
    <div class="tx_top2_relative">
		<div class="">
			<div class="tx_relative_m">
				<div class="">  
					<div class="mainmenu_width_tx  ">
						<div class="alternat-main-menu one_page hidden-xs hidden-sm witr_search_wh witr_h_h20">
							<div class="alternat_nav_area scroll_fixed postfix">
								<div class="container-fluid">
									<div class="row logo-left">		
										<!-- LOGO -->
										<div class="col-md-3 col-sm-3 col-xs-4">
											<div class="logo">
												<a class="main_sticky_main_l" href="index.html" title="Alternat">
													<img src="assets/images/logo2.png" alt="Alternat">
												</a>
												<a class="main_sticky_l" href="index.html" title="Alternat">
													<img src="assets/images/logo.png" alt="Alternat">
												</a>
											</div>	  
										</div>
										<!-- MAIN MENU -->
										<div class="col-md-9 col-sm-9 col-xs-8">
											<nav class="alternat_menu">						
												<ul class="sub-menu">
													<li><a href="index.html">Home</a></li>
													<li class="menu-item-has-children">
														<a href="#">Large Language Model</a>
														<ul class="sub-menu">
															<li><a href="LLM.html">Introduction</a></li>
															<li><a href="LLMexamples.html">Models</a></li>
														</ul>
													</li>
													<li class="menu-item-has-children">
														<a href="#">AI Chatbot</a>
														<ul class="sub-menu">
															<li><a href="Chatbot.html">Introduction</a></li>
															<li><a href="Popularchatbot.html">Popular Tools</a></li>
															<li><a href="Otherchatbot.html">Other Tools</a></li>
														</ul>
													</li>
													<li class="menu-item-has-children">
														<a href="#">Study & Knowledge</a>
														<ul class="sub-menu">
															<li><a href="LLMstudy.html">Studies of LLM</a></li>
															<li><a href="chatbotstudy.html">Studies of Chatbot</a></li>
															<li><a href="Misunderstandings.html">Misunderstandings</a></li>
														</ul>
													</li>
													<li class="menu-item-has-children">
														<a href="#">Tutorials</a>
														<ul class="sub-menu">
															<li><a href="Practice.html">General Tutorial</a></li>
															<li><a href="Personalized.html">Personalized Tutorial</a></li>
														</ul>
													</li>
												</ul>
											</nav>
										</div>
									</div>
								</div>
							</div>
						</div> 			
					</div>
				</div> 
			</div> 
		</div> 
	</div> 
</div> 



<!-- MOBILE MENU Logo AREA -->
<div class="mobile_logo_area hidden-md hidden-lg">
	<div class="container">
		<div class="row">
			<div class="col-sm-12">
				<div class="mobile_menu_logo text-center">
					<a href="index.html" title="alternat">
						<img src="assets/images/logo2.png" alt="alternat">
					</a>		
				</div>
			</div>
		</div>
	</div>
</div>

<!-- MOBILE MENU AREA -->
<div class="home-2 mbm hidden-md hidden-lg  header_area main-menu-area">
	<div class="menu_area mobile-menu">
		<nav class="alternat_menu">						
			<ul class="sub-menu">
				<li><a href="index.html">Home</a></li>
				<li class="menu-item-has-children">
					<a href="#">Large Language Model</a>
					<ul class="sub-menu">
						<li><a href="LLM.html">Introduction</a></li>
						<li><a href="LLMexamples.html">Models</a></li>
					</ul>
				</li>
				<li class="menu-item-has-children">
					<a href="#">AI Chatbot</a>
					<ul class="sub-menu">
						<li><a href="Chatbot.html">Introduction</a></li>
						<li><a href="Popularchatbot.html">Popular Tools</a></li>
						<li><a href="Otherchatbot.html">Other Tools</a></li>
					</ul>
				</li>
				<li class="menu-item-has-children">
					<a href="#">Study & Knowledge</a>
					<ul class="sub-menu">
						<li><a href="LLMstudy.html">Studies of LLM</a></li>
						<li><a href="chatbotstudy.html">Studies of Chatbot</a></li>
						<li><a href="Misunderstandings.html">Misunderstandings</a></li>
					</ul>
				</li>
				<li class="menu-item-has-children">
					<a href="#">Tutorials</a>
					<ul class="sub-menu">
						<li><a href="Practice.html">General Tutorial</a></li>
						<li><a href="Personalized.html">Personalized Tutorial</a></li>
					</ul>
				</li>
			</ul>
		</nav>
	</div>					
</div>
<!-- END MOBILE MENU AREA  -->



<!-- breadcumb-area	 -->
<div class="breadcumb-area">
	<div class="container">				
		<div class="row">
			<div class="col-md-12 txtc  text-center ccase">
				<div class="brpt">
					<h2>Misunderstandings</h2>
				</div>
				<div class="breadcumb-inner">
					<ul>
						<li><a href="index.html">Home</a></li>
						<li><i class="fas fa-angle-right"></i></li>
						<li>Misunderstandings</li>
					</ul>						
				</div>
			</div>
		</div>
	</div>
</div>

<!-- alternat_process_area -->
<div class="alternat_process_area">
	<div class="container">	
		<div class="row">
			<div class="col-lg-12">
				<div class="witr_section_title ft">
					<div class="witr_section_title_inner text-center">
						<h2 style="font-size:50px;">Are large language models really unable to reason? Three Major Misunderstandings and Truth Analysis!</h2>		
						<p>We will delve into a currently hot topic: whether large language models (LLMS) possess reasoning capabilities.</p> 
						<p>With the rapid development of artificial intelligence technology, LLMS have been widely used in various fields, but their limitations in reasoning ability have sparked many controversies. So, what exactly is the essence of these disputes?</p>
					</div>
				</div>
			</div>
		</div>
		<div class="clearfix kicuakta">
			<div class="portfolio_nav  wittr_pfilter_menu"></div>
		</div>
		<div class="container">	
			<div class="row about">
				<div class="col-md-12 col-sm-12"><!--col-lg-6-->
					<div class="witr_section_lf">
						<div class="witr_section_title">
							<div class="witr_section_title_inner text-left">
								<h3>Introduction</h3>
								<p></p>
							</div>
						</div>
						<div class="list_item_area">
							<ul>
								<li>
									<span>In the world of artificial intelligence, the introduction of large language models is undoubtedly a technological opportunity. They have demonstrated astonishing capabilities in the field of natural language processing (NLP), such as generating text, answering questions, and translating languages, and have become favored by developers and enterprises. However, although these models perform well in some applications, they have significant deficiencies in reasoning ability. Regarding this point, the viewpoint put forward by Alejandro Piad Morffis has sparked widespread discussion. </span>
								</li>
								<li>
									<span>This article will start from the concept of reasoning, further analyze the limitations of large language models, and dissect the three common misunderstandings hidden behind them. To enable readers to have a deeper understanding of this field, we will combine real cases and professional insights to make every technical detail operational, so that you can confidently deal with various challenges in future development and application. </span>
								</li>
							</ul>
						</div>
						<div class="single_image_area">
                            <div class="single_image">
                                <img src="assets/images/misunderstanding01.png" alt="">
                                <p></p>
                            </div>
                        </div>
						<div class="witr_section_title">
							<div class="witr_section_title_inner text-left">
								<h3>Reasoning Concepts in Artificial Intelligence</h3>
								<p></p>
							</div>
						</div>
						<div class="list_item_area">
							<ul>
								<li>
									<span><b>The definition of reasoning</b> is the basis for us to understand the operation of large language models. When we talk about reasoning, we do not refer to the abstract concepts at the philosophical level, but rather emphasize the understanding of specific logical behaviors within the field of artificial intelligence. </span>
								</li>
								<li>
									<span>Reasoning is usually defined as the ability to derive logical conclusions from a set of premises, mainly including two forms: deduction and induction. Deductive reasoning is a way of reasoning from general rules to specific examples, while inductive reasoning is the process of generalizing general conclusions from specific examples. Although the two have their own applications in different scenarios, in the discussion of the reasoning ability of large language models, the deductive method is often more important. </span>
								</li>
								<li>
									<span>Large language models are trained based on huge amounts of data and are capable of generating coherent and natural text responses. However, in terms of deductive reasoning, they seem relatively weak. This is because large language models actually generate output using probabilistic mechanisms rather than based on logical verification. This mode makes the model feel helpless in the face of complex reasoning tasks. For example, when confronted with simple mathematical reasoning problems, large language models may output conclusions that seem reasonable but are actually wrong. </span>
								</li>
								<li>
									<span>For those problems that require strict adherence to deductive logic, large language models cannot provide 100% accurate answers. Therefore, the deficiency of its reasoning ability is not an isolated phenomenon but the result of internal design. </span>
								</li>
							</ul>
						</div>
						<div class="witr_section_title">
							<div class="witr_section_title_inner text-left">
								<h3>Three Common Misunderstandings and Their Refutations</h3>
								<p></p>
								<h4>Misunderstanding 1: Humans also have limitations in reasoning</h4>
								<p></p>
							</div>
						</div>
						<div class="list_item_area">
							<ul>
								<li>
									<span>Many people believe that since humans can also make mistakes when reasoning, there is no need to discuss such deficiencies of large language models extensively. However, this view is obviously misleading. Although humans themselves may make mistakes in reasoning in some cases, unlike machines, humans have the ability of open-ended reasoning. </span>
								</li>
								<li>
									<span>After thousands of years of civilization development, human beings have established a strict logical and mathematical system. For instance, many well-known mathematical theorems - for example, the Pythagoras Theorem - are derived through rigorous logical reasoning. Therefore, when we compare humans with large language models, it is obvious that we should examine large language models under rigorous standards. Although the emergence of LLM has given us hope in tasks such as text generation, it is definitely a misunderstanding to regard it as a "substitute for human intelligence". </span>
								</li>
								
							</ul>
						</div>
						<div class="single_image_area">
                            <div class="single_image">
                                <img src="assets/images/misunderstanding04.png" alt="">
                                <p></p>
                            </div>
                        </div>
						<div class="list_item_area">
							<ul>
								
								<li>
									<span>Actual cases show that in some fields (such as medicine and law), precise reasoning is particularly needed because its results often concern people's life and death. In these cases, we still need to rely on human wisdom and experience instead of blindly relying on large language models. It is not so much the limitations of humans as the shortcomings of machine algorithms. While we have overly high expectations of them, we have overlooked their fundamental limitations. </span>
								</li>
								
							</ul>
						</div>
						<div class="witr_section_title">
							<div class="witr_section_title_inner text-left">
								<h4>Misunderstanding 2: Randomness is not a limitation</h4>
								<p></p>
							</div>
						</div>
						<div class="list_item_area">
							<ul>
								<li>
									<span>Some researchers believe that randomness plays an important role in solving problems. However, for large language models, this view is actually a misunderstanding. Effective reasoning not only relies on randomness but also requires a verifiable structure. In scientific algorithms, randomness is often applied to search and optimization strategies. For example, simulated annealing, which is commonly used in genetic algorithms, is an individual case. In these cases, the ability of randomness to solve complex problems is undeniable. Therefore, some people question that the criticism of the randomness of large language models is unfair. </span>
								</li>
								<li>
									<span>The key lies in understanding the relationship between the structure of reasoning and randomness. Some successful reasoning algorithms do rely on randomness in search, but their subsequent verification process is accomplished based on logic and algorithmic strictness. In large language models, the process of generating and evaluating outputs is often based on uncertainty, which makes it difficult to ensure the reliability of the results. </span>
								</li>
								<li>
									<span>Some users have reported that in the text content generated by a certain large language model they used, there were occasional sentences expressing surprise and lacking logic. Such a situation, although reflecting the flexibility of the model, also warns us of the high standards we have for the reasoning results. In key application scenarios, this imprecision may lead to the spread of incorrect information, thereby causing irreparable consequences. Therefore, in the future, AI technology needs to clearly demarcate the boundary between the application of randomness and the accuracy of reasoning. </span>
								</li>
								
							</ul>
						</div>
						<div class="single_image_area">
                            <div class="single_image">
                                <img src="assets/images/misunderstanding05.jpg" alt="">
                                <p></p>
                            </div>
                        </div>
						<div class="witr_section_title">
							<div class="witr_section_title_inner text-left">
								<h4>Misconception 3: Large language models can achieve Turing completeness</h4>
								<p></p>
							</div>
						</div>
						<div class="list_item_area">
							<ul>
								<li>
									<span>In today's technological context, "Turing completeness" is frequently mentioned. Many people believe that by appropriately connecting external tools, large language models can achieve Turing completeness. Superficially, it seems to be logical indeed, but at the implementation level, it is another matter. The superiority of machine learning lies in its flexible structure and open, non-customized way of thinking. However, when interacting with external tools, this way of thinking is greatly limited. </span>
								</li>
								
							</ul>
						</div>
						<div class="single_image_area">
                            <div class="single_image">
                                <img src="assets/images/misunderstanding02.png" alt="">
                                <p></p>
                            </div>
                        </div>
						<div class="list_item_area">
							<ul>
								
								<li>
									<span>The fixed budget of computing resources makes it impossible for large language models to solve some NP-Complete problems. In practice, if a large language model is integrated with an SAT solver, the possible results may still rely on the reasoning ability of the model itself. This high degree of dependence leads to the model being difficult to achieve the expected results in practical applications, especially when dealing with complex reasoning. </span>
								</li>
								<li>
									<span>A certain AI start-up company attempted to combine its model with a graphical algorithm tool. During complex reasoning, it created a misjudgment, resulting in incorrect information being uploaded to the client, causing a waste of time and resources. Under such circumstances, although Turing completeness was theoretically achieved, it actually raised more serious responsibility issues. </span>
								</li>
								<li>
									<span>Even though the integration of external tools to make large language models Turing complete seems highly successful, the key lies in whether these tools can be fully and effectively utilized. The improvement of model stability and interaction ability is the problem that we urgently need to solve. </span>
								</li>
							</ul>
						</div>
						<div class="witr_section_title">
							<div class="witr_section_title_inner text-left">
								<h4>Summarize the viewpoints</h4>
								<p></p>
							</div>
						</div>
						<div class="list_item_area">
							<ul>
								<li>
									<span>The reasoning ability of large language models still faces numerous challenges, and these limitations become increasingly evident as technology continues to deepen. It is necessary for us to take these challenges seriously and attach importance to the optimization and improvement of large language models. Future research and development should focus on improving the verification ability of the model, optimizing the reasoning structure, and enhancing the stability of the algorithm, etc., in order to meet the strict requirements in complex application scenarios. </span>
								</li>
								<li>
									<span>In real development practice, we should not blindly rely on the popular technologies in the market. Instead, we should maintain a rational and critical attitude, and deeply analyze the logic and principles behind each technology. Only in this way can we remain invincible in the future technological opportunities. </span>
								</li>
								
							</ul>
						</div>
						<div class="single_image_area">
                            <div class="single_image">
                                <img src="assets/images/misunderstanding03.jpg" alt="">
                                <p></p>
                            </div>
                        </div>
						<div class="witr_section_title">
							<div class="witr_section_title_inner text-left">
								<h4>The future direction of discussion</h4>
								<p></p>
							</div>
						</div>
						<div class="list_item_area">
							<ul>
								<li>
									<span>If we hope that large language models can better serve us in the future, we need to clarify the gap between technological innovation and actual demands. To address the shortcomings of LLMS, we can start from three aspects: </span>
								</li>
								<li>
									<span><i class="far fa-flag"></i></span>
									<span>Introduction of verification mechanism: Traditional logical reasoning tools are adopted and combined with large language models to conduct result verification. This process will take into account the advantages of both. </span>
								</li>
								<li>
									<span><i class="far fa-flag"></i></span>
									<span>Enhance the stability of the model: Improve the stability of the model during the reasoning process through ensemble learning and meta-learning methods to reduce the generation of illogical incorrect expressions. </span>
								</li>
								<li>
									<span><i class="far fa-flag"></i></span>
									<span>Multimodal learning: By integrating multiple technologies such as image recognition and voice recognition, and introducing knowledge graphs to provide external knowledge support for the model, it can make more reasonable inferences in complex situations. </span>
								</li>
								<li>
									<span>In the process of technological iteration, our goal is to constantly absorb cutting-edge theories and practical experiences in order to launch large language models with high performance, large capacity and greater reliability in the future. We believe that through continuous in-depth research and development, we will eventually overcome the existing deficiencies and enable large language models to play an important role in a wider range of application scenarios. </span>
								</li>
							</ul>
						</div>
						
					</div>
				</div>
			</div>
		</div>
		<div class="clearfix kicuakta">
			<div class="portfolio_nav  wittr_pfilter_menu"></div>
		</div>
		
	</div>
</div>
		

	
<!-- witrfm_footer_area -->
<div class="witrfm_area">
	<div class="footer-middle">  
		<div class="container">
			<div class="row">
				<div class="col-sm-12 col-md-6  col-lg-3 ">
					<div class="widget about_us">
						<div class="about-footer">
							<div class="footer-widget address">
								<div class="footer-logo">
									<img src="assets/images/logo.png" alt="">
									<p>The relevant information of LLM and AI Chatbot.</p>
								</div>
								<div class="footer-address">
									<div class="footer_s_inner"> 
										<div class="footer-sociala-icon">
											<i class="fa fa-map-marker"></i>
										</div>									
										<div class="footer-sociala-info">				
											<p>HKBU AIDM Program</p>
										</div> 
									</div> 
									<div class="footer_s_inner"> 
										<div class="footer-sociala-icon">
											<i class="fa fa-phone"></i>
										</div> 									
										<div class="footer-sociala-info">   
												<p>(+852) 3411 5127</p>
										</div>
									</div>
									<div class="footer_s_inner"> 
										<div class="footer-sociala-icon"> 
											<i class="fa fa-globe"></i>
										</div> 
										<div class="footer-sociala-info">  
											<p>hkbu_tpg@hkbu.edu.hk</p>									
										</div>
									</div>
								</div>
							</div>
						</div>	
					</div>	
				</div>
				<div class="col-sm-12 col-md-6  col-lg-3 ">
					<div class="widget widget_text">
						<h2 class="widget-title">Categories</h2>	
						<div class="textwidget">
							<div class="witr_table">
								<div class="witr_sub_table">
									<span> LLM: Introduction & Models</span>
								</div>
								<div class="witr_sub_table">
									<span>AI Chatbot: Introduction & Tools</span>
								</div>
								<div class="witr_sub_table">
									<span>Study & Knowledge: Findings & Misunderstandings</span>
								</div>
								<div class="witr_sub_table">
									<span>Tutorials: Simple & Personalized</span>
								</div>
							</div>
						</div>
					</div>				
				</div>
				<div class="col-lg-3  col-md-6 col-sm-12 last">
					<div class="widget widget_carousel_port_data">	
						<div class="single_carousel_item">
							<h2 class="widget-title">Related contents </h2>				
							<div class="carousel-portfolio-area">
								<div class="witr_footer_carousel">
									<div class="recent-portfolio">
										<div class="recent-portfolio-image">
											<a href="LLMS01.html"><img src="assets/images/LLMS01.png"  alt=""></a>
										</div>
									</div>
									<div class="recent-portfolio">
										<div class="recent-portfolio-image">
											<a href="AICS03.html"><img src="assets/images/AICS03.png"  alt=""></a>
										</div>
									</div>
									<div class="recent-portfolio">
										<div class="recent-portfolio-image">
											<a href="AICS02.html"><img src="assets/images/AICS02.png"  alt=""></a>
										</div>
									</div>
								</div>
							</div>
						</div>
					</div>
				</div>	
				<div class="col-sm-12 col-md-6  col-lg-3 last">
					<div class="widget widget_recent_data">	
						<div class="single-widget-item">
							<h2 class="widget-title">Resent Posts</h2>				
								<!--<div class="recent-post-item">
									<div class="recent-post-image">
									<a href="LLMS01.html"><img src="assets/images/recent-thumb-01.jpg"  alt=""></a>
								</div>
								<div class="recent-post-text">
									<h4><a href="LLMS01.html">A Survey on LLM-Generated Text Detection: Necessity, Methods, and Future Directions</a></h4>
									<span class="rcomment">15 March, 2025</span>
								</div>-->
							</div>
							<div class="recent-post-item">
								<div class="recent-post-image">
									<a href="LLMS02.html"><img src="assets/images/LLMS02-1.png"  alt=""></a>
								</div>
								<div class="recent-post-text">
									<h4><a href="LLMS02.html">LLM Post-Training: A Deep Dive into Reasoning Large Language Models</a></h4>
									<span class="rcomment">28 February, 2025</span>
								</div>
							</div>
							<div class="recent-post-item">
								<div class="recent-post-image">
									<a href="LLMS05.html"><img src="assets/images/LLMS05-1.png"  alt=""></a>
								</div>
								<div class="recent-post-text">
									<h4><a href="LLMS05.html">LLM Fine-Tuning: Concepts, Opportunities, and Challenges</a></h4>
									<span class="rcomment">02 April, 2025</span>
								</div>
							</div>
						</div>
					</div>					
				</div>
			</div>	
		</div>	
	</div>	
</div>



        <!-- Include All JS -->
        <script src="assets/js/vendor/jquery-3.5.1.min.js"></script>
        <script src="assets/js/bootstrap.min.js"></script>
        <script src="assets/js/isotope.pkgd.min.js"></script>
        <script src="assets/js/owl.carousel.min.js"></script>
        <script src="assets/js/jquery.nivo.slider.pack.js"></script>
        <script src="assets/js/slick.min.js"></script>
        <script src="assets/js/imagesloaded.pkgd.min.js"></script>
        <script src="venobox/venobox.min.js"></script>
        <script src="assets/js/jquery.appear.js"></script>
        <script src="assets/js/jquery.knob.js"></script>
        <script src="assets/js/BeerSlider.js"></script>
        <script src="assets/js/theme-pluginjs.js"></script>
        <script src="assets/js/jquery.meanmenu.js"></script>
        <script src="assets/js/ajax-mail.js"></script>		
        <script src="assets/js/theme.js"></script>
	
	</body>
</html>